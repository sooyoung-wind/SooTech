{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, log_loss, roc_auc_score\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score, matthews_corrcoef, balanced_accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifierCV, Perceptron, SGDClassifier, RidgeClassifier, PassiveAggressiveClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import NearestCentroid, KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import category_encoders as ce\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the dataset\n",
    "titanic = pd.read_csv(\"./sample_data/train.csv\")\n",
    "titanic = titanic.drop([\"PassengerId\", \"Name\", \"Cabin\", \"Ticket\"], axis=1)\n",
    "titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].mean())\n",
    "titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna(titanic[\"Embarked\"].mode()[0])\n",
    "X = titanic.drop([\"Survived\"], axis=1)\n",
    "y = titanic[\"Survived\"]\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=21)\n",
    "# Encode categorical variables\n",
    "encoder = ce.OrdinalEncoder([\"Sex\", \"Embarked\"])\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "X_test = encoder.transform(X_test)\n",
    "# Define models\n",
    "models = {\n",
    "\"Logistic Regression\": LogisticRegression(),\n",
    "\"Random Forest\": RandomForestClassifier(criterion=\"entropy\", n_estimators=100),\n",
    "\"LightGBM\": lgb.LGBMClassifier(),\n",
    "\"Ridge Classifier CV\": RidgeClassifierCV(),\n",
    "\"XGBoost\": XGBClassifier(),\n",
    "\"Nearest Centroid\": NearestCentroid(),\n",
    "\"Quadratic Discriminant Analysis\": QuadraticDiscriminantAnalysis(),\n",
    "\"Calibrated Classifier CV\": CalibratedClassifierCV(),\n",
    "\"Bernoulli NB\": BernoulliNB(),\n",
    "\"Bagging Classifier\": BaggingClassifier(),\n",
    "\"SVC\": SVC(),\n",
    "\"Linear SVC\": LinearSVC(),\n",
    "\"KNeighbors Classifier\": KNeighborsClassifier(),\n",
    "\"Gaussian NB\": GaussianNB(),\n",
    "\"Perceptron\": Perceptron(),\n",
    "\"SGD Classifier\": SGDClassifier(),\n",
    "\"Decision Tree\": DecisionTreeClassifier(),\n",
    "\"MLP Classifier\": MLPClassifier(),\n",
    "\"Extra Trees\": ExtraTreesClassifier(),\n",
    "\"AdaBoost\": AdaBoostClassifier(),\n",
    "\"Nu SVC\": NuSVC(),\n",
    "\"Gaussian Process\": GaussianProcessClassifier(kernel=RBF()),\n",
    "\"Ridge Classifier\": RidgeClassifier(),\n",
    "\"Passive Aggressive\": PassiveAggressiveClassifier(),\n",
    "\"Hist Gradient Boosting\": HistGradientBoostingClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 268, number of negative: 444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 204\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.376404 -> initscore=-0.504838\n",
      "[LightGBM] [Info] Start training from score -0.504838\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "# Train and predict\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Calculate metrics\n",
    "    CM = confusion_matrix(y_test, y_pred)\n",
    "    TN, FP, FN, TP = CM.ravel()\n",
    "    specificity = TN / (TN + FP)\n",
    "    loss_log = log_loss(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    mathew = matthews_corrcoef(y_test, y_pred)\n",
    "    results.append([name, acc, balanced_acc, prec, rec, specificity, f1, roc, loss_log, mathew])\n",
    "    model_results = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Balanced Accuracy\", \"Precision\", \"Recall\", \"Sensitivity\", \"F1\", \"ROC\", \"Log Loss\", \"Mathew\"])\n",
    "    model_results = model_results.sort_values(\"F1\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC</th>\n",
       "      <th>Log Loss</th>\n",
       "      <th>Mathew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.825997</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.794326</td>\n",
       "      <td>0.825997</td>\n",
       "      <td>5.839475</td>\n",
       "      <td>0.663450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.821236</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.788732</td>\n",
       "      <td>0.821236</td>\n",
       "      <td>6.040836</td>\n",
       "      <td>0.651851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.818468</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.786207</td>\n",
       "      <td>0.818468</td>\n",
       "      <td>6.242197</td>\n",
       "      <td>0.641159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP Classifier</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.809717</td>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.876190</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.809717</td>\n",
       "      <td>6.443558</td>\n",
       "      <td>0.628477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.807722</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.807722</td>\n",
       "      <td>6.443558</td>\n",
       "      <td>0.628185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gaussian NB</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.802960</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.876190</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.802960</td>\n",
       "      <td>6.644919</td>\n",
       "      <td>0.616566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.800965</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.716216</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.762590</td>\n",
       "      <td>0.800965</td>\n",
       "      <td>6.644919</td>\n",
       "      <td>0.616379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Calibrated Classifier CV</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.800965</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.716216</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.762590</td>\n",
       "      <td>0.800965</td>\n",
       "      <td>6.644919</td>\n",
       "      <td>0.616379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hist Gradient Boosting</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.798198</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.760563</td>\n",
       "      <td>0.798198</td>\n",
       "      <td>6.846281</td>\n",
       "      <td>0.605103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.794208</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.794208</td>\n",
       "      <td>6.846281</td>\n",
       "      <td>0.604584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.794208</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.794208</td>\n",
       "      <td>6.846281</td>\n",
       "      <td>0.604584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ridge Classifier CV</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.794208</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.794208</td>\n",
       "      <td>6.846281</td>\n",
       "      <td>0.604584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bagging Classifier</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.792214</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.792214</td>\n",
       "      <td>6.846281</td>\n",
       "      <td>0.604856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.788674</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.788674</td>\n",
       "      <td>7.249003</td>\n",
       "      <td>0.582621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Nu SVC</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.788674</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.788674</td>\n",
       "      <td>7.249003</td>\n",
       "      <td>0.582621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.783140</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.783140</td>\n",
       "      <td>7.651725</td>\n",
       "      <td>0.564179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Quadratic Discriminant Analysis</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.787452</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.787452</td>\n",
       "      <td>7.047642</td>\n",
       "      <td>0.592797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Passive Aggressive</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.769949</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.635135</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.717557</td>\n",
       "      <td>0.769949</td>\n",
       "      <td>7.450364</td>\n",
       "      <td>0.570695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.765363</td>\n",
       "      <td>0.756113</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.756113</td>\n",
       "      <td>8.457170</td>\n",
       "      <td>0.514416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.748456</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.554054</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.677686</td>\n",
       "      <td>0.748456</td>\n",
       "      <td>7.853086</td>\n",
       "      <td>0.556101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KNeighbors Classifier</td>\n",
       "      <td>0.698324</td>\n",
       "      <td>0.671042</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.671042</td>\n",
       "      <td>10.873504</td>\n",
       "      <td>0.363327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Gaussian Process</td>\n",
       "      <td>0.703911</td>\n",
       "      <td>0.663835</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.547009</td>\n",
       "      <td>0.663835</td>\n",
       "      <td>10.672143</td>\n",
       "      <td>0.377698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Nearest Centroid</td>\n",
       "      <td>0.648045</td>\n",
       "      <td>0.612227</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.612227</td>\n",
       "      <td>12.685755</td>\n",
       "      <td>0.247894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.664804</td>\n",
       "      <td>0.616538</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.616538</td>\n",
       "      <td>12.081672</td>\n",
       "      <td>0.286344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Bernoulli NB</td>\n",
       "      <td>0.558659</td>\n",
       "      <td>0.506113</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.275229</td>\n",
       "      <td>0.506113</td>\n",
       "      <td>15.907534</td>\n",
       "      <td>0.015181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model  Accuracy  Balanced Accuracy  Precision  \\\n",
       "0                     Random Forest  0.837989           0.825997   0.835821   \n",
       "1                           XGBoost  0.832402           0.821236   0.823529   \n",
       "2                       Extra Trees  0.826816           0.818468   0.802817   \n",
       "3                    MLP Classifier  0.821229           0.809717   0.808824   \n",
       "4                          LightGBM  0.821229           0.807722   0.818182   \n",
       "5                       Gaussian NB  0.815642           0.802960   0.805970   \n",
       "6                        Linear SVC  0.815642           0.800965   0.815385   \n",
       "7          Calibrated Classifier CV  0.815642           0.800965   0.815385   \n",
       "8            Hist Gradient Boosting  0.810056           0.798198   0.794118   \n",
       "9               Logistic Regression  0.810056           0.794208   0.812500   \n",
       "10                 Ridge Classifier  0.810056           0.794208   0.812500   \n",
       "11              Ridge Classifier CV  0.810056           0.794208   0.812500   \n",
       "12               Bagging Classifier  0.810056           0.792214   0.822581   \n",
       "13                         AdaBoost  0.798883           0.788674   0.771429   \n",
       "14                           Nu SVC  0.798883           0.788674   0.771429   \n",
       "15                       Perceptron  0.787709           0.783140   0.736842   \n",
       "16  Quadratic Discriminant Analysis  0.804469           0.787452   0.809524   \n",
       "17               Passive Aggressive  0.793296           0.769949   0.824561   \n",
       "18                    Decision Tree  0.765363           0.756113   0.722222   \n",
       "19                   SGD Classifier  0.782123           0.748456   0.872340   \n",
       "20            KNeighbors Classifier  0.698324           0.671042   0.678571   \n",
       "21                 Gaussian Process  0.703911           0.663835   0.744186   \n",
       "22                 Nearest Centroid  0.648045           0.612227   0.612245   \n",
       "23                              SVC  0.664804           0.616538   0.694444   \n",
       "24                     Bernoulli NB  0.558659           0.506113   0.428571   \n",
       "\n",
       "      Recall  Sensitivity        F1       ROC   Log Loss    Mathew  \n",
       "0   0.756757     0.895238  0.794326  0.825997   5.839475  0.663450  \n",
       "1   0.756757     0.885714  0.788732  0.821236   6.040836  0.651851  \n",
       "2   0.770270     0.866667  0.786207  0.818468   6.242197  0.641159  \n",
       "3   0.743243     0.876190  0.774648  0.809717   6.443558  0.628477  \n",
       "4   0.729730     0.885714  0.771429  0.807722   6.443558  0.628185  \n",
       "5   0.729730     0.876190  0.765957  0.802960   6.644919  0.616566  \n",
       "6   0.716216     0.885714  0.762590  0.800965   6.644919  0.616379  \n",
       "7   0.716216     0.885714  0.762590  0.800965   6.644919  0.616379  \n",
       "8   0.729730     0.866667  0.760563  0.798198   6.846281  0.605103  \n",
       "9   0.702703     0.885714  0.753623  0.794208   6.846281  0.604584  \n",
       "10  0.702703     0.885714  0.753623  0.794208   6.846281  0.604584  \n",
       "11  0.702703     0.885714  0.753623  0.794208   6.846281  0.604584  \n",
       "12  0.689189     0.895238  0.750000  0.792214   6.846281  0.604856  \n",
       "13  0.729730     0.847619  0.750000  0.788674   7.249003  0.582621  \n",
       "14  0.729730     0.847619  0.750000  0.788674   7.249003  0.582621  \n",
       "15  0.756757     0.809524  0.746667  0.783140   7.651725  0.564179  \n",
       "16  0.689189     0.885714  0.744526  0.787452   7.047642  0.592797  \n",
       "17  0.635135     0.904762  0.717557  0.769949   7.450364  0.570695  \n",
       "18  0.702703     0.809524  0.712329  0.756113   8.457170  0.514416  \n",
       "19  0.554054     0.942857  0.677686  0.748456   7.853086  0.556101  \n",
       "20  0.513514     0.828571  0.584615  0.671042  10.873504  0.363327  \n",
       "21  0.432432     0.895238  0.547009  0.663835  10.672143  0.377698  \n",
       "22  0.405405     0.819048  0.487805  0.612227  12.685755  0.247894  \n",
       "23  0.337838     0.895238  0.454545  0.616538  12.081672  0.286344  \n",
       "24  0.202703     0.809524  0.275229  0.506113  15.907534  0.015181  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
